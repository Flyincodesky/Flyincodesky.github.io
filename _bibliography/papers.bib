@comment{---
---}

@inproceedings{chen2023co,
 abbr = {MICCAI},
 abstract = {Abstract placeholder...},
 author = {Chen, Xuan and Fu, Weiheng and Li, Tian and Shi*, Xiaoshuang and Shen, Hengtao and Zhu, Xiaofeng},
 bibtex_show = {true},
 booktitle = {International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
 code = {None},
 note = {CCF-B},
 pages = {159--168},
 pdf = {true},
 title = {Co-assistant Networks for Label Correction},
 year = {2023}
}

@inproceedings{duan2023improve,
 abbr = {IJCAI},
 abstract = {Abstract placeholder...},
 author = {Duan, Jinhao and Fan, Quanfu and Cheng, Hao and Shi*, Xiaoshuang and Xu*, Kaidi},
 bibtex_show = {true},
 booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},
 code = {None},
 note = {CCF-A},
 pages = {708--716},
 pdf = {true},
 title = {Improve video representation with temporal adversarial augmentation},
 year = {2023}
}

@inproceedings{huang2024on,
 abbr = {ICML},
 abstract = {The label smoothness assumption is at the core of Graph Convolutional Networks (GCNs): nodes in a local region have similar labels. Thus, GCN performs local feature smoothing operation to adhere to this assumption. However, there exist some nodes whose labels obtained by feature smoothing conflict with the label smoothness assumption. We find that the label smoothness assumption and the process of feature smoothing are both problematic on these nodes, and call these nodes out of GCN's control (OOC nodes). In this paper, first, we design the corresponding algorithm to locate the OOC nodes, then we summarize the characteristics of OOC nodes that affect their representation learning, and based on their characteristics, we present DaGCN, an efficient framework that can facilitate the OOC nodes. Extensive experiments verify the superiority of the proposed method and demonstrate that current advanced GCNs are improvements specifically on OOC nodes; the remaining nodes under GCN's control (UC nodes) are already optimally represented by vanilla GCN on most datasets.},
 author = {Huang, Jincheng and Shen, Jialie and Shi*, Xiaoshuang and Zhu*, Xiaofeng},
 bibtex_show = {true},
 booktitle = {International Conference on Machine Learning (ICML)},
 preview = {huang2024on.png},
 note = {CCF-A},
 pdf = {huang2024on.pdf},
 selected = {true},
 title = {On Which Nodes Does GCN Fail? Enhancing GCN From the Node Perspective},
 year = {2024}
}

@article{jin2025dynamic,
 abbr = {MIA},
 abstract = {Abstract placeholder...},
 author = {Jin, Haochen and Shen, Junyi and Cui, Lei and Shi*, Xiaoshuang and Li*, Kang and Zhu, Xiaofeng},
 bibtex_show = {true},
 code = {None},
 journal = {Medical Image Analysis},
 note = {中科院JCR一区},
 pages = {103468},
 pdf = {true},
 title = {Dynamic graph based weakly supervised deep hashing for whole slide image classification and retrieval},
 year = {2025}
}

@inproceedings{kong2024act,
 abbr = {CVPR},
 abstract = {Though diffusion models excel in image generation, their step-by-step denoising leads to slow generation speeds. Consistency training addresses this issue with single-step sampling but often produces lower-quality generations and requires high training costs. In this paper, we show that optimizing consistency training loss minimizes the Wasserstein distance between target and generated distributions. As timestep increases, the upper bound accumulates previous consistency training losses. Therefore, larger batch sizes are needed to reduce both current and accumulated losses. We propose Adversarial Consistency Training (ACT), which directly minimizes the Jensen-Shannon (JS) divergence between distributions at each timestep using a discriminator. Theoretically, ACT enhances generation quality, and convergence. By incorporating a discriminator into the consistency training framework, our method achieves improved FID scores on CIFAR10 and ImageNet 64×64 and LSUN Cat 256×256 datasets, retains zero-shot image inpainting capabilities, and uses less than 1/6 of the original batch size and fewer than 1/2 of the model parameters and training steps compared to the baseline method, this leads to a substantial reduction in resource consumption. Our code is available:https://github.com/kong13661/ACT},
 author = {Kong, Fei and Duan, Jinhao and Sun, Lichao and Cheng, Hao and Xu, Renjing and Shen, Hengtao and Zhu, Xiaofeng and Shi*, Xiaoshuang and Xu*, Kaidi},
 bibtex_show = {true},
 booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
 code = {https://github.com/kong13661/ACT},
 note = {CCF-A},
 pages = {8890--8899},
 pdf = {kong2024act.pdf},
 preview = {first_page/kong2024act.jpg},
 selected = {true},
 title = {ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models},
 year = {2024}
}

@article{li2022fsnet,
 abbr = {TETCI},
 abstract = {Graph Convolutional Networks (GCNs) have been successfully applied... (Abstract placeholder)},
 author = {Li+, Hengxin and Shi+, Xiaoshuang and Zhu, Xiaofeng and Wang, Shuihua and Zhang, Zheng},
 bibtex_show = {true},
 code = {None},
 journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
 note = {中科院JCR二区},
 pdf = {true},
 title = {FSNet: Dual Interpretable Graph Convolutional Network for Alzheimer's Disease Analysis},
 year = {2022}
}

@inproceedings{mo2022simple,
 abbr = {AAAI},
 abstract = {Abstract placeholder...},
 author = {Mo, Yujie and Peng, Liang and Xu, Jie and Shi*, Xiaoshuang and Zhu, Xiaofeng},
 bibtex_show = {true},
 booktitle = {AAAI Conference on Artificial Intelligence},
 code = {None},
 note = {CCF-A},
 pdf = {true},
 title = {Simple Unsupervised Graph Representation Learning},
 year = {2022}
}

@article{peng2022reverse,
 abbr = {TNNLS},
 abstract = {Abstract placeholder...},
 author = {Peng, Liang and Hu, Rongyao and Kong, Fei and Gan, Jiangzhang and Mo, Yujie and Shi*, Xiaoshuang and Zhu*, Xiaofeng},
 bibtex_show = {true},
 code = {None},
 journal = {IEEE Transactions on Neural Networks and Learning Systems},
 note = {中科院JCR一区},
 pdf = {true},
 title = {Reverse Graph Learning for Graph Neural Network},
 year = {2022}
}

@article{shi2014face,
 abbr = {PR},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Yang, Yujiu and Guo, Zhenhua and Lai, Zhihui},
 bibtex_show = {true},
 code = {None},
 journal = {Pattern Recognition},
 note = {中科院JCR一区},
 number = {7},
 pages = {2447--2453},
 pdf = {true},
 title = {Face recognition by sparse discriminant analysis via joint L2,1-norm minimization},
 volume = {47},
 year = {2014}
}

@article{shi2015framework,
 abbr = {TIP},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Guo, Zhenhua and Lai, Zhihui and Yang, Yujiu and Bao, Zhifeng and Zhang, David},
 bibtex_show = {true},
 code = {None},
 journal = {IEEE Transactions on Image Processing},
 note = {中科院JCR一区},
 number = {4},
 pages = {1341--1355},
 pdf = {true},
 title = {A Framework of Joint Graph Embedding and Sparse Regression for Dimensionality Reduction},
 volume = {24},
 year = {2015}
}

@inproceedings{shi2016kernel,
 abbr = {ECCV},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Xing, Fuyong and Cai, Jinzheng and Zhang, Zizhao and Xie, Yuanpu and Yang, Lin},
 bibtex_show = {true},
 booktitle = {European Conference on Computer Vision (ECCV)},
 code = {None},
 note = {~26\% acceptance rate, CCF-B},
 pages = {419--433},
 pdf = {true},
 title = {Kernel-based supervised discrete hashing for image retrieval},
 year = {2016}
}

@article{shi2016two,
 abbr = {TPAMI},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Guo, Zhenhua and Nie, Feiping and Yang, Lin and You, Jane and Tao, Dacheng},
 bibtex_show = {true},
 code = {None},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 note = {中科院JCR一区},
 number = {10},
 pages = {2130--2136},
 pdf = {true},
 title = {Two-Dimensional Whitening Reconstruction for Enhancing Robustness of Principal Component Analysis},
 volume = {38},
 year = {2016}
}

@inproceedings{shi2017asymmetric,
 abbr = {AAAI},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Xing, Fuyong and Xu, Kaidu and Sapkota, Manish and Yang, Lin},
 bibtex_show = {true},
 booktitle = {AAAI Conference on Artificial Intelligence},
 code = {None},
 note = {Spotlight, ~25\% acceptance rate, CCF-A},
 pages = {2541--2547},
 pdf = {true},
 title = {Asymmetric discrete graph hashing},
 year = {2017}
}

@inproceedings{shi2017cell,
 abbr = {MICCAI},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Xing, Fuyong and Xie, Yuanpu and Yang, Lin},
 bibtex_show = {true},
 booktitle = {International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)},
 code = {None},
 note = {~32\% acceptance rate, CCF-B},
 pages = {30--38},
 pdf = {true},
 title = {Cell encoding for histopathology image classification},
 year = {2017}
}

@article{shi2017supervised,
 abbr = {MIA},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Xing, Fuyong and Xu, Kaidi and Xie, Yuanpu and Su, Hai and Yang, Lin},
 bibtex_show = {true},
 code = {None},
 journal = {Medical Image Analysis},
 note = {中科院JCR一区},
 pages = {117--128},
 pdf = {true},
 title = {Supervised graph hashing for histopathology image retrieval and classification},
 volume = {42},
 year = {2017}
}

@article{shi2018pairwise,
 abbr = {PR},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Sapkota, Manish and Xing, Fuyong and Liu, Fujun and Cui, Lei and Yang, Lin},
 bibtex_show = {true},
 code = {None},
 journal = {Pattern Recognition},
 note = {中科院JCR一区},
 pages = {14--22},
 pdf = {true},
 title = {Pairwise based deep ranking hashing for histopathology image classification and retrieval},
 volume = {81},
 year = {2018}
}

@article{shi2018self,
 abbr = {PR},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Guo, Zhenhua and Xing, Fuyong and Cai, Jinzheng and Yang, Lin},
 bibtex_show = {true},
 code = {None},
 journal = {Pattern Recognition},
 note = {中科院JCR一区},
 pages = {279--289},
 pdf = {true},
 title = {Self-learning for face clustering},
 volume = {79},
 year = {2018}
}

@article{shi2020anchor,
 abbr = {IJCV},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Guo, Zhenhua and Xing, Fuyong and Liang, Yu and Yang, Lin},
 bibtex_show = {true},
 code = {None},
 journal = {International Journal of Computer Vision},
 note = {CCF-A},
 pages = {1-18},
 pdf = {true},
 title = {Anchor-Based Self-Ensembling for Semi-Supervised Deep Pairwise Hashing},
 year = {2020}
}

@article{shi2020graph,
 abbr = {MIA},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Su, Hai and Xing, Fuyong and Liang, Yun and Qu, Gang and Yang, Lin},
 bibtex_show = {true},
 code = {None},
 journal = {Medical Image Analysis},
 note = {中科院JCR一区},
 pages = {101624},
 pdf = {true},
 title = {Graph temporal ensembling based semi-supervised convolutional neural network with noisy labels for histopathology image analysis},
 volume = {60},
 year = {2020}
}

@inproceedings{shi2020loss,
 abbr = {AAAI},
 abstract = {Although attention mechanisms have been widely used in deep learning for many tasks, they are rarely utilized to solve multiple instance learning (MIL) problems, where only a general category label is given for multiple instances contained in one bag. Additionally, previous deep MIL methods firstly utilize the attention mechanism to learn instance weights and then employ a fully connected layer to predict the bag label, so that the bag prediction is largely determined by the effectiveness of learned instance weights. To alleviate this issue, in this paper, we propose a novel loss based attention mechanism, which simultaneously learns instance weights and predictions, and bag predictions for deep multiple instance learning. Specifically, it calculates instance weights based on the loss function, e.g. softmax+cross-entropy, and shares the parameters with the fully connected layer, which is to predict instance and bag predictions. Additionally, a regularization term consisting of learned weights and cross-entropy functions is utilized to boost the recall of instances, and a consistency cost is used to smooth the training process of neural networks for boosting the model generalization performance. Extensive experiments on multiple types of benchmark databases demonstrate that the proposed attention mechanism is a general, effective and efficient framework, which can achieve superior bag and image classification performance over other state-of-the-art MIL methods, with obtaining higher instance precision and recall than previous attention mechanisms. Source codes are available on https://github.com/xsshi2015/Loss-Attention.},
 author = {Shi, Xiaoshuang and Xing, Fuyong and Xie, Yuanpu and Zhang, Zizhao and Cui, Lei and Yang, Lin},
 bibtex_show = {true},
 booktitle = {AAAI Conference on Artificial Intelligence},
 code = {https://github.com/xsshi2015/Loss-Attention},
 note = {Spotlight, ~20\% acceptance rate, CCF-A},
 pdf = {shi2020loss.pdf},
 preview = {losebase.png},
 selected = {true},
 title = {Loss-based attention for deep multiple instance learning},
 year = {2020}
}

@article{shi2021loss,
 abbr = {TIP},
 abstract = {Although deep neural networks have achieved great success on numerous large-scale tasks, poor interpretability is still a notorious obstacle for practical applications. In this paper, we propose a novel and general attention mechanism, loss-based attention, upon which we modify deep neural networks to mine significant image patches for explaining which parts determine the image decision-making. This is inspired by the fact that some patches contain significant objects or their parts for image-level decision. Unlike previous attention mechanisms that adopt different layers and parameters to learn weights and image prediction, the proposed loss-based attention mechanism mines significant patches by utilizing the same parameters to learn patch weights and logits (class vectors), and image prediction simultaneously, so as to connect the attention mechanism with the loss function for boosting the patch precision and recall. Additionally, different from previous popular networks that utilize max-pooling or stride operations in convolutional layers without considering the spatial relationship of features, the modified deep architectures first remove them to preserve the spatial relationship of image patches and greatly reduce their dependencies, and then add two convolutional or capsule layers to extract their features. With the learned patch weights, the image-level decision of the modified deep architectures is the weighted sum on patches. Extensive experiments on large-scale benchmark databases.},
 author = {Shi, Xiaoshuang and Xing, Fuyong and Xu, Kaidi and Chen, Pingjun and Liang, Yun and Lu, Zhiyong and Guo, Zhenhua},
 bibtex_show = {true},
 code = {https://github.com/xsshi2015/Loss-based-Attention-for-Interpreting-Image-level-Prediction-of-Convolutional-Neural-Networks},
 journal = {IEEE Transactions on Image Processing},
 note = {CCF-A},
 pages = {1662--1675},
 pdf = {shi2021loss.pdf},
 preview = {shi2021loss.png},
 selected = {true},
 title = {Loss-based Attention for Interpreting Image-level Prediction of Convolutional Neural Networks},
 volume = {30},
 year = {2021}
}

@article{shi2021scalable,
 abbr = {TIP},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Xing, Fuyong and Zhang, Zizhao and Sapkota, Manish and Guo, Zhenhua and Yang, Lin},
 bibtex_show = {true},
 code = {None},
 journal = {IEEE Transactions on Image Processing},
 note = {中科院JCR一区},
 pages = {1130--1142},
 pdf = {true},
 title = {A Scalable Optimization Mechanism for Pairwise based Discrete Hashing},
 volume = {30},
 year = {2021}
}

@article{shi2022robust,
 abbr = {PR},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Peng, Yifan and Chen, Qingyu, et al.},
 bibtex_show = {true},
 code = {None},
 journal = {Pattern Recognition},
 note = {中科院JCR一区},
 pages = {108923},
 pdf = {true},
 title = {Robust convolutional neural networks against adversarial attacks on medical images},
 volume = {132},
 year = {2022}
}

@article{shi2022self,
 abbr = {PR},
 abstract = {Abstract placeholder...},
 author = {Shi, Xiaoshuang and Guo, Zhenhua and Li, Kang and Liang, Yun and Zhu, Xiaofeng},
 bibtex_show = {true},
 code = {None},
 journal = {Pattern Recognition},
 note = {中科院JCR一区},
 pages = {109080},
 pdf = {true},
 title = {Self-paced Resistance Learning against Overfitting on Noisy Labels},
 year = {2022}
}

@inproceedings{sun2024caterpillar,
 abbr = {ACM MM},
 abstract = {Modeling in Computer Vision has evolved to MLPs. Vision MLPs naturally lack local modeling capability, to which the simplest treatment is combined with convolutional layers. Convolution, famous for its sliding window scheme, also suffers from this scheme of redundancy and low computational efficiency. In this paper, we seek to dispense with the windowing scheme and introduce a more elaborate and effective approach to exploiting locality. To this end, we propose a new MLP module, namely Shifted-Pillars-Concatenation (SPC), that consists of two steps of processes: (1) Pillars-Shift, which generates four neighboring maps by shifting the input image along four directions, and (2) Pillars-Concatenation, which applies linear transformations and concatenation on the maps to aggregate local features. SPC module offers superior local modeling power and performance gains, making it a promising alternative to the convolutional layer. Then, we build a pure-MLP architecture called Caterpillar by replacing the convolutional layer with the SPC module in a hybrid model of sMLPNet. Extensive experiments show Caterpillar's excellent performance and scalability on both ImageNet-1K and small-scale classification benchmarks.},
 author = {Sun, Jin and Shi*, Xiaoshuang and Wang, Zhiyuan and Xu, Kaidi and Shen, Heng Tao and Zhu, Xiaofeng},
 bibtex_show = {true},
 booktitle = {Proceedings of the ACM International Conference on Multimedia (ACM MM)},
 code = {https://github.com/sunjin19126/Caterpillar},
 note = {CCF-A},
 pages = {7123--7132},
 pdf = {sun2024caterpillar.pdf},
 preview = {sun2024caterpillar.png},
 selected = {true},
 title = {Caterpillar: A Pure-MLP Architecture with Shifted-Pillars-Concatenation},
 year = {2024}
}

@inproceedings{wang2025sconu,
 abbr = {ACL},
 abstract = {As large language models are increasingly utilized in real-world applications, guarantees of task-specific metrics are essential for their reliable deployment. Previous studies have introduced various criteria of conformal uncertainty grounded in split conformal prediction, which offer user-specified correctness coverage. However, existing frameworks often fail to identify uncertainty data outliers that violate the exchangeability assumption, leading to unbounded miscoverage rates and unactionable prediction sets. In this paper, we propose a novel approach termed Selective Conformal Uncertainty (SConU), which, for the first time, implements significance tests, by developing two conformal p-values that are instrumental in determining whether a given sample deviates from the uncertainty distribution of the calibration set at a specific manageable risk level. Our approach not only facilitates rigorous management of miscoverage rates across both single-domain and interdisciplinary contexts, but also enhances the efficiency of predictions. Furthermore, we comprehensively analyze the components of the conformal procedures, aiming to approximate conditional coverage, particularly in high-stakes question-answering tasks.},
 author = {Wang, Zhiyuan and Wang, Qingni and Zhang, Yue and Chen, Tianlong and Zhu, Xiaofeng and Shi*, Xiaoshuang and Xu*, Kaidi},
 bibtex_show = {true},
 booktitle = {The Annual Meeting of the Association for Computational Linguistics (ACL)},
 code = {https://github.com/Zhiyuan-GG/SConU},
 note = {CCF-A},
 preview = {wang2025sconu.png},
 pdf = {wang2025sconu.pdf},
 selected = {true},
 title = {SConU: Selective Conformal Uncertainty in Large Language Models},
 year = {2025}
}

@article{wang2025word,
 abbr = {EAAI},
 abstract = {Abstract placeholder...},
 author = {Wang, Zhiyuan and Duan, Jinhao and Yuan, Chenxi and Chen, Qingyu and Chen, Tianlong and Zhang, Yue and Wang, Ren and Shi*, Xiaoshuang and Xu, Kaidi},
 bibtex_show = {true},
 code = {None},
 journal = {Engineering Applications of Artificial Intelligence},
 note = {中科院JCR一区},
 pages = {109553},
 pdf = {true},
 title = {Word-sequence entropy: Towards uncertainty estimation in free-form medical question answering applications and beyond},
 volume = {139},
 year = {2025}
}

@article{xiang2023multi,
 abbr = {MIA},
 abstract = {Abstract placeholder...},
 author = {Xiang, Hangchen and Shen, Junyi and Yan, Qingguo and Xu*, Meilian and Shi*, Xiaoshuang and Zhu, Xiaofeng},
 bibtex_show = {true},
 code = {None},
 journal = {Medical Image Analysis},
 note = {中科院JCR一区},
 pages = {102890},
 pdf = {true},
 title = {Multi-scale representation attention based deep multiple instance learning for gigapixel whole slide image analysis},
 volume = {89},
 year = {2023}
}

@inproceedings{xiao2022dual,
 abbr = {MICCAI},
 abstract = {Abstract placeholder...},
 author = {Xiao, Tingsong and Zeng, Lu and Shi*, Xiaoshuang and Zhu*, Xiaofeng and Wu, Guorong},
 bibtex_show = {true},
 booktitle = {International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
 code = {None},
 note = {CCF-B},
 pages = {406--415},
 pdf = {true},
 title = {Dual-graph learning convolutional networks for interpretable alzheimer’s disease diagnosis},
 year = {2022}
}

@inproceedings{xu2022deep,
 abbr = {AAAI},
 abstract = {Abstract placeholder...},
 author = {Xu, Jie and Li, Chao and Ren*, Yazhou and Peng, Liang and Mo, Yujie and Shi*, Xiaoshuang and Zhu, Xiaofeng},
 bibtex_show = {true},
 booktitle = {AAAI Conference on Artificial Intelligence},
 code = {None},
 note = {CCF-A},
 pdf = {true},
 title = {Deep Incomplete Multi-View Clustering via Mining Cluster Complementarity},
 year = {2022}
}

@article{xu2024interpretable,
 abbr = {PR},
 abstract = {Abstract placeholder...},
 author = {Xu, Jinghao and Yuan, Chenxi and Ma, Xiaochuan and Shang*, Huifang and Shi*, Xiaoshuang and Zhu, Xiaofeng},
 bibtex_show = {true},
 code = {None},
 journal = {Pattern Recognition},
 note = {中科院JCR一区},
 pages = {110450},
 pdf = {true},
 title = {Interpretable medical deep framework by logits-constraint attention guiding graph-based multi-scale fusion for Alzheimer’s disease analysis},
 volume = {152},
 year = {2024}
}

@article{xu2025interpretable2,
 abbr = {InfoFusion},
 abstract = {Abstract placeholder...},
 author = {Xu, Jinghao and Yuan, Chenxi and Jing, Yi and Shang*, Huifang and Shi*, Xiaoshuang and Zhu, Xiaofeng},
 bibtex_show = {true},
 code = {None},
 journal = {Information Fusion},
 note = {中科院JCR一区},
 pages = {103579},
 pdf = {true},
 title = {Interpretable multi-view fusion network via multi-view dual alignment and private bias filtering for Alzheimer’s disease analysis},
 year = {2025}
}

@article{zeng2024feature,
 abbr = {TNNLS},
 abstract = {Abstract placeholder...},
 author = {Zeng, Lu and Chen, Xuan and Shi*, Xiaoshuang and Shen, Heng Tao},
 bibtex_show = {true},
 code = {None},
 journal = {IEEE Transactions on Neural Networks and Learning Systems},
 note = {中科院JCR一区},
 pdf = {true},
 title = {Feature Noise Boosts DNN Generalization Under Label Noise},
 year = {2024}
}

@article{zhan2023igcnn,
 abbr = {IPM},
 abstract = {Abstract placeholder...},
 author = {Zhan, Mengmeng and Shi*, Xiaoshuang and Liu, Fangqi and Hu, Rongyao},
 bibtex_show = {true},
 code = {None},
 journal = {Information Processing & Management},
 note = {中科院JCR一区},
 pages = {103258},
 pdf = {true},
 title = {IGCNN-FC: Boosting interpretability and generalization of convolutional neural networks for few chest X-rays analysis},
 volume = {60},
 year = {2023}
}
