<!DOCTYPE html> <html lang="zh-CN"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> TIM Lab </title> <meta name="author" content="Xiaoshuang Shi"> <meta name="description" content="可信智能医疗实验室 (Trust Intelligent Medical Lab) - 电子科技大学计算机科学与工程学院（网络空间安全学院）。主要研究方向是机器学习、模式识别、多模态医学数据分析。 "> <meta name="keywords" content="实验室, 研究, 机器学习, 模式识别, 医学数据分析, 电子科技大学, 石小爽"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%AC&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://flyincodesky.github.io/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> TIM Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">首页 <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/team/">团队成员 </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">研究项目 </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">论文成果 </a> </li> <li class="nav-item "> <a class="nav-link" href="/activities/">活动与新闻 </a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">联系我们 </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> TIM Lab </h1> <p class="desc">可信智能医疗实验室 (Trust Intelligent Medical Lab) - 致力于研究可信可解释的人工智能模型并能够有效的辅助临床医学诊断</p> </header> <article> <div class="clearfix"> <style>body{font-family:"Times New Roman","SimSun","宋体","STSong",serif}</style> <h2 id="实验室简介">实验室简介</h2> <p>欢迎来到可信智能医疗实验室（Trust Intelligent Medical Lab），本实验室成立于2021年，隶属于电子科技大学计算机科学与工程学院（网络空间安全学院）。</p> <p>主要研究方向是<strong>机器学习</strong>、<strong>模式识别</strong>、<strong>多模态医学数据分析</strong>。致力于从特征选择和模型优化的角度构建可信可解释的人工智能模型以有效的处理多模态临床医学数据，包括病理切片、神经影像、临床文本等，同时模型可以在不同的应用场景具有良好的可泛化性。</p> <p>我们拥有一支充满活力和创新精神的科研团队，与国内外知名高校和研究机构保持紧密合作，期待与更多优秀人才共同探索科技前沿。</p> <hr> <h2 id="导师简介">导师简介</h2> <div id="shixiaoshuang" class="row mt-3 "> <div class="col-sm-3 mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/shixiaoshuang-480.webp 480w,/assets/img/shixiaoshuang-800.webp 800w,/assets/img/shixiaoshuang-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/shixiaoshuang.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-9 mt-3 mt-md-0"> <h4>石小爽 教授 (Xiaoshuang Shi)</h4> <p><strong>教授、博士生导师、国家青年特聘专家</strong></p> <p>电子科技大学计算机科学与工程学院（网络空间安全学院）</p> <p><strong>研究方向：</strong>机器学习、模式识别、多模态医学数据分析</p> <p> 石小爽是电子科技大学教授，博士生导师，国家青年特聘专家。主要研究方向为机器学习、模式识别、医学数据分析。致力于解决视觉图像检索和分类中的特征编码与理解的问题，针对降低大数据计算和存储成本、解释图像重要特征、特征提取的鲁棒性等关键问题进行了深入的研究，在哈希编码优化、可解释深度神经网络和图学习等方法的理论以及医学应用上取得了多个创新性的研究成果。近年来，累计在模式识别、计算机视觉和医学数据分析领域发表学术论文90余篇，其中TPAMI、IJCV、TIP、MIA、MICCAI等CCF-A类、中科院JCR-1区以及医学图像领域顶级会议发表论文70余篇（含CCF-A类、中科院JCR-1区一作和通讯作者30余篇），Google引用超过4000次。获得华为人才Funding, 先后主持国家自然科学基金面上项目1项，科技部重点研发/重大专项子课题2项和四川省科技厅面上项目1项。 </p> <p> <a href="/cv/">查看完整简历</a> | <a href="mailto:xsshi2021@uestc.edu.cn">xsshi2021@uestc.edu.cn</a> | <a href="https://scholar.google.com/citations?user=BWGQt3YAAAAJ&amp;hl=en" target="_blank" rel="external nofollow noopener">Google Scholar</a> </p> </div> </div> <hr> <h2 id="重点项目">重点项目</h2> <div class="projects"> <div class="row"> <div class="col-sm-6 mt-3"> <div class="card hoverable"> <div class="card-body"> <h5 class="card-title">视觉图像特征编码和理解</h5> <p class="card-text"> 针对降低大数据计算和存储成本、解释图像重要特征、特征提取的鲁棒性等关键问题进行了深入的研究。 </p> <p class="card-text"><small class="text-muted">2023.01-2025.12 | 国家自然科学基金项目</small></p> <a href="/projects/" class="btn btn-sm btn-primary">了解更多</a> </div> </div> </div> <div class="col-sm-6 mt-3"> <div class="card hoverable"> <div class="card-body"> <h5 class="card-title">数字病理切片自动标注和检索</h5> <p class="card-text"> 基于弱监督深度学习的方法，解决数字病理切片分析中的自动标注和检索问题， 提高病理诊断的效率和准确性。 </p> <p class="card-text"><small class="text-muted">2023.01-2026.12 | 国家自然科学基金面上项目</small></p> <a href="/projects/" class="btn btn-sm btn-primary">了解更多</a> </div> </div> </div> </div> <div class="row"> <div class="col-sm-6 mt-3"> <div class="card hoverable"> <div class="card-body"> <h5 class="card-title">支持机器学习自动化的元学习</h5> <p class="card-text"> 研究支持机器学习自动化的元学习理论与应用，探索如何通过元学习实现机器学习模型的快速适应和自动化构建。 </p> <p class="card-text"><small class="text-muted">2022.12-2027.11 | 科技部重点研发子课题</small></p> <a href="/projects/" class="btn btn-sm btn-primary">了解更多</a> </div> </div> </div> <div class="col-sm-6 mt-3"> <div class="card hoverable"> <div class="card-body"> <h5 class="card-title">慢病诊疗医学决定水平研究</h5> <p class="card-text"> 针对重大慢病诊疗中的关键检验项目，研究医学决定水平的建立与应用，为慢病诊疗提供科学依据。 </p> <p class="card-text"><small class="text-muted">2025.08-2029.07 | 科技部重大专项子课题</small></p> <a href="/projects/" class="btn btn-sm btn-primary">了解更多</a> </div> </div> </div> </div> </div> <hr> <h2 id="近期代表性论文">近期代表性论文</h2> <p>我们的研究成果已在多个顶级国际会议和期刊上发表。以下是部分代表性论文：</p> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> <figure> <picture> <img src="/assets/img/publication_preview/huang2024on.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="huang2024on.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="huang2024on" class="col-sm-8"> <div class="title">On Which Nodes Does GCN Fail? Enhancing GCN From the Node Perspective</div> <div class="author"> Jincheng Huang, Jialie Shen, Xiaoshuang Shi<sup>*</sup>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Xiaofeng Zhu&lt;sup&gt;*&lt;/sup&gt;' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2024 </div> <div class="periodical"> CCF-A </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/huang2024on.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The label smoothness assumption is at the core of Graph Convolutional Networks (GCNs): nodes in a local region have similar labels. Thus, GCN performs local feature smoothing operation to adhere to this assumption. However, there exist some nodes whose labels obtained by feature smoothing conflict with the label smoothness assumption. We find that the label smoothness assumption and the process of feature smoothing are both problematic on these nodes, and call these nodes out of GCN’s control (OOC nodes). In this paper, first, we design the corresponding algorithm to locate the OOC nodes, then we summarize the characteristics of OOC nodes that affect their representation learning, and based on their characteristics, we present DaGCN, an efficient framework that can facilitate the OOC nodes. Extensive experiments verify the superiority of the proposed method and demonstrate that current advanced GCNs are improvements specifically on OOC nodes; the remaining nodes under GCN’s control (UC nodes) are already optimally represented by vanilla GCN on most datasets.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang2024on</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Jincheng and Shen, Jialie and Shi, Xiaoshuang and Zhu, Xiaofeng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{CCF-A}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On Which Nodes Does GCN Fail? Enhancing GCN From the Node Perspective}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <img src="/assets/img/publication_preview/first_page/kong2024act.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="first_page/kong2024act.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kong2024act" class="col-sm-8"> <div class="title">ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models</div> <div class="author"> Fei Kong, Jinhao Duan, Lichao Sun, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Hao Cheng, Renjing Xu, Hengtao Shen, Xiaofeng Zhu, Xiaoshuang Shi&lt;sup&gt;*&lt;/sup&gt;, Kaidi Xu&lt;sup&gt;*&lt;/sup&gt;' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024 </div> <div class="periodical"> CCF-A </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/kong2024act.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/kong13661/ACT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Though diffusion models excel in image generation, their step-by-step denoising leads to slow generation speeds. Consistency training addresses this issue with single-step sampling but often produces lower-quality generations and requires high training costs. In this paper, we show that optimizing consistency training loss minimizes the Wasserstein distance between target and generated distributions. As timestep increases, the upper bound accumulates previous consistency training losses. Therefore, larger batch sizes are needed to reduce both current and accumulated losses. We propose Adversarial Consistency Training (ACT), which directly minimizes the Jensen-Shannon (JS) divergence between distributions at each timestep using a discriminator. Theoretically, ACT enhances generation quality, and convergence. By incorporating a discriminator into the consistency training framework, our method achieves improved FID scores on CIFAR10 and ImageNet 64×64 and LSUN Cat 256×256 datasets, retains zero-shot image inpainting capabilities, and uses less than 1/6 of the original batch size and fewer than 1/2 of the model parameters and training steps compared to the baseline method, this leads to a substantial reduction in resource consumption. Our code is available:https://github.com/kong13661/ACT</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kong2024act</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kong, Fei and Duan, Jinhao and Sun, Lichao and Cheng, Hao and Xu, Renjing and Shen, Hengtao and Zhu, Xiaofeng and Shi, Xiaoshuang and Xu, Kaidi}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{CCF-A}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8890--8899}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <img src="/assets/img/publication_preview/losebase.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="losebase.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="shi2020loss" class="col-sm-8"> <div class="title">Loss-based attention for deep multiple instance learning</div> <div class="author"> Xiaoshuang Shi, Fuyong Xing, Yuanpu Xie, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Zizhao Zhang, Lei Cui, Lin Yang' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In AAAI Conference on Artificial Intelligence</em>, 2020 </div> <div class="periodical"> Spotlight,  20% acceptance rate, CCF-A </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/shi2020loss.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/xsshi2015/Loss-Attention" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Although attention mechanisms have been widely used in deep learning for many tasks, they are rarely utilized to solve multiple instance learning (MIL) problems, where only a general category label is given for multiple instances contained in one bag. Additionally, previous deep MIL methods firstly utilize the attention mechanism to learn instance weights and then employ a fully connected layer to predict the bag label, so that the bag prediction is largely determined by the effectiveness of learned instance weights. To alleviate this issue, in this paper, we propose a novel loss based attention mechanism, which simultaneously learns instance weights and predictions, and bag predictions for deep multiple instance learning. Specifically, it calculates instance weights based on the loss function, e.g. softmax+cross-entropy, and shares the parameters with the fully connected layer, which is to predict instance and bag predictions. Additionally, a regularization term consisting of learned weights and cross-entropy functions is utilized to boost the recall of instances, and a consistency cost is used to smooth the training process of neural networks for boosting the model generalization performance. Extensive experiments on multiple types of benchmark databases demonstrate that the proposed attention mechanism is a general, effective and efficient framework, which can achieve superior bag and image classification performance over other state-of-the-art MIL methods, with obtaining higher instance precision and recall than previous attention mechanisms. Source codes are available on https://github.com/xsshi2015/Loss-Attention.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">shi2020loss</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shi, Xiaoshuang and Xing, Fuyong and Xie, Yuanpu and Zhang, Zizhao and Cui, Lei and Yang, Lin}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Spotlight, ~20\% acceptance rate, CCF-A}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Loss-based attention for deep multiple instance learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TIP</abbr> <figure> <picture> <img src="/assets/img/publication_preview/shi2021loss.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="shi2021loss.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="shi2021loss" class="col-sm-8"> <div class="title">Loss-based Attention for Interpreting Image-level Prediction of Convolutional Neural Networks</div> <div class="author"> Xiaoshuang Shi, Fuyong Xing, Kaidi Xu, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Pingjun Chen, Yun Liang, Zhiyong Lu, Zhenhua Guo' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>IEEE Transactions on Image Processing</em>, 2021 </div> <div class="periodical"> CCF-A </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/shi2021loss.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/xsshi2015/Loss-based-Attention-for-Interpreting-Image-level-Prediction-of-Convolutional-Neural-Networks" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Although deep neural networks have achieved great success on numerous large-scale tasks, poor interpretability is still a notorious obstacle for practical applications. In this paper, we propose a novel and general attention mechanism, loss-based attention, upon which we modify deep neural networks to mine significant image patches for explaining which parts determine the image decision-making. This is inspired by the fact that some patches contain significant objects or their parts for image-level decision. Unlike previous attention mechanisms that adopt different layers and parameters to learn weights and image prediction, the proposed loss-based attention mechanism mines significant patches by utilizing the same parameters to learn patch weights and logits (class vectors), and image prediction simultaneously, so as to connect the attention mechanism with the loss function for boosting the patch precision and recall. Additionally, different from previous popular networks that utilize max-pooling or stride operations in convolutional layers without considering the spatial relationship of features, the modified deep architectures first remove them to preserve the spatial relationship of image patches and greatly reduce their dependencies, and then add two convolutional or capsule layers to extract their features. With the learned patch weights, the image-level decision of the modified deep architectures is the weighted sum on patches. Extensive experiments on large-scale benchmark databases.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">shi2021loss</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shi, Xiaoshuang and Xing, Fuyong and Xu, Kaidi and Chen, Pingjun and Liang, Yun and Lu, Zhiyong and Guo, Zhenhua}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Image Processing}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{CCF-A}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1662--1675}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Loss-based Attention for Interpreting Image-level Prediction of Convolutional Neural Networks}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{30}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACM MM</abbr> <figure> <picture> <img src="/assets/img/publication_preview/sun2024caterpillar.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sun2024caterpillar.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sun2024caterpillar" class="col-sm-8"> <div class="title">Caterpillar: A Pure-MLP Architecture with Shifted-Pillars-Concatenation</div> <div class="author"> Jin Sun, Xiaoshuang Shi<sup>*</sup>, Zhiyuan Wang, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Kaidi Xu, Heng Tao Shen, Xiaofeng Zhu' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the ACM International Conference on Multimedia (ACM MM)</em>, 2024 </div> <div class="periodical"> CCF-A </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/sun2024caterpillar.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/sunjin19126/Caterpillar" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Modeling in Computer Vision has evolved to MLPs. Vision MLPs naturally lack local modeling capability, to which the simplest treatment is combined with convolutional layers. Convolution, famous for its sliding window scheme, also suffers from this scheme of redundancy and low computational efficiency. In this paper, we seek to dispense with the windowing scheme and introduce a more elaborate and effective approach to exploiting locality. To this end, we propose a new MLP module, namely Shifted-Pillars-Concatenation (SPC), that consists of two steps of processes: (1) Pillars-Shift, which generates four neighboring maps by shifting the input image along four directions, and (2) Pillars-Concatenation, which applies linear transformations and concatenation on the maps to aggregate local features. SPC module offers superior local modeling power and performance gains, making it a promising alternative to the convolutional layer. Then, we build a pure-MLP architecture called Caterpillar by replacing the convolutional layer with the SPC module in a hybrid model of sMLPNet. Extensive experiments show Caterpillar’s excellent performance and scalability on both ImageNet-1K and small-scale classification benchmarks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sun2024caterpillar</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Jin and Shi, Xiaoshuang and Wang, Zhiyuan and Xu, Kaidi and Shen, Heng Tao and Zhu, Xiaofeng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the ACM International Conference on Multimedia (ACM MM)}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{CCF-A}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7123--7132}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Caterpillar: A Pure-MLP Architecture with Shifted-Pillars-Concatenation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACL</abbr> <figure> <picture> <img src="/assets/img/publication_preview/wang2025sconu.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wang2025sconu.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2025sconu" class="col-sm-8"> <div class="title">SConU: Selective Conformal Uncertainty in Large Language Models</div> <div class="author"> Zhiyuan Wang, Qingni Wang, Yue Zhang, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Tianlong Chen, Xiaofeng Zhu, Xiaoshuang Shi&lt;sup&gt;*&lt;/sup&gt;, Kaidi Xu&lt;sup&gt;*&lt;/sup&gt;' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In The Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2025 </div> <div class="periodical"> CCF-A </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/wang2025sconu.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/Zhiyuan-GG/SConU" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>As large language models are increasingly utilized in real-world applications, guarantees of task-specific metrics are essential for their reliable deployment. Previous studies have introduced various criteria of conformal uncertainty grounded in split conformal prediction, which offer user-specified correctness coverage. However, existing frameworks often fail to identify uncertainty data outliers that violate the exchangeability assumption, leading to unbounded miscoverage rates and unactionable prediction sets. In this paper, we propose a novel approach termed Selective Conformal Uncertainty (SConU), which, for the first time, implements significance tests, by developing two conformal p-values that are instrumental in determining whether a given sample deviates from the uncertainty distribution of the calibration set at a specific manageable risk level. Our approach not only facilitates rigorous management of miscoverage rates across both single-domain and interdisciplinary contexts, but also enhances the efficiency of predictions. Furthermore, we comprehensively analyze the components of the conformal procedures, aiming to approximate conditional coverage, particularly in high-stakes question-answering tasks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2025sconu</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Zhiyuan and Wang, Qingni and Zhang, Yue and Chen, Tianlong and Zhu, Xiaofeng and Shi, Xiaoshuang and Xu, Kaidi}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Annual Meeting of the Association for Computational Linguistics (ACL)}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{CCF-A}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SConU: Selective Conformal Uncertainty in Large Language Models}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Aug 01, 2025</th> <td> 主持 <strong>科技部重大专项子课题</strong>：重大慢病诊疗关键检验项目医学决定水平的建立与应用研究 (2025.08-2029.07). </td> </tr> <tr> <th scope="row" style="width: 20%">May 01, 2025</th> <td> 论文 <em>SConU: Selective Conformal Uncertainty in Large Language Models</em> 被 <strong>ACL 2025 (CCF-A)</strong> 录用. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 01, 2024</th> <td> 论文 <em>ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models</em> 被 <strong>CVPR 2024 (CCF-A)</strong> 录用. </td> </tr> <tr> <th scope="row" style="width: 20%">May 01, 2024</th> <td> 论文 <em>On Which Nodes Does GCN Fail? Enhancing GCN From the Node Perspective</em> 被 <strong>ICML 2024 (CCF-A)</strong> 录用. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 02, 2023</th> <td> 主持 <strong>国家自然科学基金面上项目</strong>：基于弱监督深度学习的数字病理切片的自动标注和检索 (2023.01-2026.12). </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 01, 2023</th> <td> 获得 <strong>国家自然科学基金项目</strong>：视觉图像特征编码和理解 (2023.01-2025.12). </td> </tr> </table> </div> </div> <div class="social"> <div class="contact-icons"> <a href="/cv/" title="CV" target="_blank"><i class="ai ai-cv"></i></a> <a href="mailto:%78%73%73%68%69%32%30%32%31@%75%65%73%74%63.%65%64%75.%63%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=BWGQt3YAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <div class="contact-note">欢迎通过邮件或电话联系我们 </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © 2026 可信智能医疗实验室. All rights reserved. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>